# ì´ˆ ë‹¨ìœ„ë¡œ ì´ë²¤íŠ¸ ê´€ì°°

#!/usr/bin/env python3
import subprocess
import json
import time
from datetime import datetime
import threading

class KubernetesEventsAnalyzer:
    def __init__(self):
        self.pod_events = {}
        self.container_states = {}
        self.timing_analysis = {}
        
    def analyze_pod_startup(self):
        """Kubernetes ì´ë²¤íŠ¸ë¥¼ í†µí•œ íŒŒë“œ ì‹œì‘ ë¶„ì„"""
        
        print("=== Kubernetes Events Based Cold Startup Analysis ===")
        print("Environment: minikube -p istio with Bookinfo")
        
        # 1. í˜„ì¬ ìƒíƒœ í™•ì¸
        self.check_current_state()
        
        # 2. ì´ë²¤íŠ¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self.start_event_monitoring()
        
        # 3. ìˆœì°¨ì  íŒŒë“œ ì¬ì‹œì‘
        self.restart_pods_sequentially()
        
        # 4. ë¶„ì„ ë° ê²°ê³¼
        time.sleep(60)  # ì¶©ë¶„í•œ ì•ˆì •í™” ì‹œê°„
        self.generate_analysis()
    
    def check_current_state(self):
        """í˜„ì¬ íŒŒë“œ ë° ì´ë²¤íŠ¸ ìƒíƒœ í™•ì¸"""
        print("\nCurrent Bookinfo Pods Status:")
        
        result = subprocess.run([
            'kubectl', 'get', 'pods', '-o', 'wide'
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')[1:]  # í—¤ë” ì œì™¸
            for line in lines:
                if any(service in line for service in ['productpage', 'details', 'reviews', 'ratings']):
                    parts = line.split()
                    pod_name = parts[0]
                    ready = parts[1]
                    status = parts[2]
                    age = parts[4]
                    print(f"  {pod_name}: {ready} {status} (age: {age})")
    
    def start_event_monitoring(self):
        """Kubernetes ì´ë²¤íŠ¸ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§"""
        print("\nStarting Kubernetes events monitoring...")
        
        def monitor_events():
            try:
                process = subprocess.Popen([
                    'kubectl', 'get', 'events', '--watch', '-o', 'json'
                ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
                
                for line in process.stdout:
                    try:
                        event = json.loads(line)
                        self.process_kubernetes_event(event)
                    except json.JSONDecodeError:
                        continue
            except Exception as e:
                print(f"Event monitoring error: {e}")
        
        monitor_thread = threading.Thread(target=monitor_events)
        monitor_thread.daemon = True
        monitor_thread.start()
        
        time.sleep(3)  # ëª¨ë‹ˆí„°ë§ ì•ˆì •í™”
    
    def process_kubernetes_event(self, event):
        """Kubernetes ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        event_type = event.get('type', '')
        reason = event.get('reason', '')
        message = event.get('message', '')
        timestamp = event.get('firstTimestamp', event.get('eventTime', ''))
        
        involved_object = event.get('involvedObject', {})
        pod_name = involved_object.get('name', '')
        object_kind = involved_object.get('kind', '')
        
        # Pod ê´€ë ¨ ì´ë²¤íŠ¸ë§Œ ì²˜ë¦¬
        if object_kind != 'Pod':
            return
            
        # Bookinfo íŒŒë“œë§Œ ì¶”ì 
        if not any(service in pod_name for service in ['productpage', 'details', 'reviews', 'ratings']):
            return
        
        timestamp_ms = self.parse_k8s_timestamp(timestamp)
        
        if pod_name not in self.pod_events:
            self.pod_events[pod_name] = []
        
        event_data = {
            'timestamp_ms': timestamp_ms,
            'reason': reason,
            'message': message,
            'type': event_type
        }
        
        self.pod_events[pod_name].append(event_data)
        
        # ì¤‘ìš”í•œ ì´ë²¤íŠ¸ë§Œ ì¶œë ¥
        important_reasons = ['Scheduled', 'Pulling', 'Pulled', 'Created', 'Started', 'Ready']
        if reason in important_reasons:
            service = self.extract_service_name(pod_name)
            print(f"[{timestamp_ms:.3f}ms] {service} - {reason}: {message[:50]}...")
    
    def parse_k8s_timestamp(self, timestamp_str):
        """Kubernetes íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ë°€ë¦¬ì´ˆë¡œ ë³€í™˜"""
        try:
            if 'T' in timestamp_str:
                dt = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
                return dt.timestamp() * 1000
        except:
            pass
        return time.time() * 1000
    
    def extract_service_name(self, pod_name):
        """íŒŒë“œ ì´ë¦„ì—ì„œ ì„œë¹„ìŠ¤ ì´ë¦„ ì¶”ì¶œ"""
        for service in ['productpage', 'details', 'reviews', 'ratings']:
            if service in pod_name:
                return service
        return 'unknown'
    
    def restart_pods_sequentially(self):
        """ì„œë¹„ìŠ¤ë³„ ìˆœì°¨ì  íŒŒë“œ ì¬ì‹œì‘"""
        services = ['productpage', 'details', 'ratings', 'reviews']
        
        print("\n=== Sequential Pod Restart for Cold Start Analysis ===")
        
        for service in services:
            print(f"\nRestarting {service} service...")
            
            # ì¬ì‹œì‘ ì‹œì‘ ì‹œê°„ ê¸°ë¡
            restart_start = time.time() * 1000
            
            # íŒŒë“œ ì‚­ì œ
            subprocess.run(['kubectl', 'delete', 'pods', '-l', f'app={service}'])
            
            # íŒŒë“œ ì¤€ë¹„ ëŒ€ê¸°
            try:
                subprocess.run([
                    'kubectl', 'wait', '--for=condition=ready', 'pod',
                    '-l', f'app={service}', '--timeout=120s'
                ], check=True)
                
                restart_end = time.time() * 1000
                restart_duration = restart_end - restart_start
                
                print(f"{service} restart completed in {restart_duration:.3f}ms")
                
                # ìƒˆ íŒŒë“œ ìƒì„¸ ë¶„ì„
                self.analyze_new_pods(service, restart_start)
                
            except subprocess.CalledProcessError:
                print(f"Timeout waiting for {service} to be ready")
            
            time.sleep(10)  # ë‹¤ìŒ ì¬ì‹œì‘ ì „ ëŒ€ê¸°
    
    def analyze_new_pods(self, service, restart_start_time):
        """ìƒˆë¡œ ìƒì„±ëœ íŒŒë“œì˜ ìƒì„¸ ë¶„ì„"""
        try:
            # í•´ë‹¹ ì„œë¹„ìŠ¤ì˜ ìƒˆ íŒŒë“œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            result = subprocess.run([
                'kubectl', 'get', 'pods', '-l', f'app={service}', '-o', 'json'
            ], capture_output=True, text=True)
            
            if result.returncode == 0:
                pods_data = json.loads(result.stdout)
                
                for pod in pods_data['items']:
                    pod_name = pod['metadata']['name']
                    creation_time = pod['metadata']['creationTimestamp']
                    
                    # ì»¨í…Œì´ë„ˆ ìƒíƒœ ë¶„ì„
                    self.analyze_container_startup_times(pod_name, pod, restart_start_time)
                    
        except Exception as e:
            print(f"Error analyzing new pods for {service}: {e}")
    
    def analyze_container_startup_times(self, pod_name, pod_data, restart_start):
        """ê°œë³„ ì»¨í…Œì´ë„ˆì˜ ì‹œì‘ ì‹œê°„ ë¶„ì„"""
        
        # íŒŒë“œ ìƒì„± ì‹œê°„
        creation_timestamp = pod_data['metadata']['creationTimestamp']
        creation_time_ms = self.parse_k8s_timestamp(creation_timestamp)
        
        # ì»¨í…Œì´ë„ˆ ìƒíƒœ ì •ë³´
        container_statuses = pod_data.get('status', {}).get('containerStatuses', [])
        
        analysis = {
            'pod_name': pod_name,
            'service': self.extract_service_name(pod_name),
            'restart_start_ms': restart_start,
            'pod_creation_ms': creation_time_ms,
            'scheduling_delay_ms': creation_time_ms - restart_start,
            'containers': []
        }
        
        for container in container_statuses:
            container_name = container['name']
            is_ready = container.get('ready', False)
            restart_count = container.get('restartCount', 0)
            
            container_analysis = {
                'name': container_name,
                'ready': is_ready,
                'restart_count': restart_count,
                'is_sidecar': container_name == 'istio-proxy'
            }
            
            # ì‹¤í–‰ ìƒíƒœ ì •ë³´
            if 'state' in container and 'running' in container['state']:
                started_at = container['state']['running'].get('startedAt', '')
                if started_at:
                    started_time_ms = self.parse_k8s_timestamp(started_at)
                    container_analysis['started_at_ms'] = started_time_ms
                    container_analysis['startup_delay_ms'] = started_time_ms - creation_time_ms
            
            analysis['containers'].append(container_analysis)
        
        # ì „ì²´ ì¤€ë¹„ ì‹œê°„ ê³„ì‚°
        if all(c['ready'] for c in analysis['containers']):
            current_time = time.time() * 1000
            analysis['total_ready_time_ms'] = current_time - restart_start
        
        self.timing_analysis[pod_name] = analysis
        
        # ì¦‰ì‹œ ì¶œë ¥
        print(f"\n*** {pod_name} TIMING ANALYSIS ***")
        print(f"Service: {analysis['service']}")
        print(f"Scheduling Delay: {analysis['scheduling_delay_ms']:.3f}ms")
        
        for container in analysis['containers']:
            container_type = "Sidecar" if container['is_sidecar'] else "Main App"
            startup_time = container.get('startup_delay_ms', 0)
            print(f"  {container['name']} ({container_type}): {startup_time:.3f}ms")
        
        if 'total_ready_time_ms' in analysis:
            print(f"Total Ready Time: {analysis['total_ready_time_ms']:.3f}ms")
    
    def generate_analysis(self):
        """ìµœì¢… ë¶„ì„ ê²°ê³¼ ìƒì„±"""
        print("\n" + "="*60)
        print("KUBERNETES EVENTS BASED COLD STARTUP ANALYSIS")
        print("="*60)
        
        if not self.timing_analysis:
            print("âŒ No timing analysis data collected")
            return
        
        # ì„œë¹„ìŠ¤ë³„ ë¶„ì„
        service_data = {}
        for pod_name, analysis in self.timing_analysis.items():
            service = analysis['service']
            if service not in service_data:
                service_data[service] = []
            service_data[service].append(analysis)
        
        # ì„œë¹„ìŠ¤ë³„ í†µê³„
        for service, analyses in service_data.items():
            print(f"\nğŸ”¹ {service.upper()} SERVICE ANALYSIS:")
            
            # ìŠ¤ì¼€ì¤„ë§ ì§€ì—°
            scheduling_delays = [a['scheduling_delay_ms'] for a in analyses if 'scheduling_delay_ms' in a]
            if scheduling_delays:
                avg_scheduling = sum(scheduling_delays) / len(scheduling_delays)
                print(f"  Average Scheduling Delay: {avg_scheduling:.3f}ms")
            
            # ì»¨í…Œì´ë„ˆë³„ ë¶„ì„
            main_containers = []
            sidecar_containers = []
            
            for analysis in analyses:
                for container in analysis['containers']:
                    startup_time = container.get('startup_delay_ms', 0)
                    if container['is_sidecar']:
                        sidecar_containers.append(startup_time)
                    else:
                        main_containers.append(startup_time)
            
            if main_containers:
                avg_main = sum(main_containers) / len(main_containers)
                print(f"  Average Main Container Startup: {avg_main:.3f}ms")
            
            if sidecar_containers:
                avg_sidecar = sum(sidecar_containers) / len(sidecar_containers)
                print(f"  Average Sidecar Startup: {avg_sidecar:.3f}ms")
            
            # ì „ì²´ ì¤€ë¹„ ì‹œê°„
            total_times = [a.get('total_ready_time_ms', 0) for a in analyses if 'total_ready_time_ms' in a]
            if total_times:
                avg_total = sum(total_times) / len(total_times)
                print(f"  Average Total Ready Time: {avg_total:.3f}ms")
        
        # ê²°ê³¼ ì €ì¥
        output_data = {
            'analysis_timestamp': datetime.now().isoformat(),
            'analysis_method': 'kubernetes_events',
            'environment': 'minikube-istio-bookinfo',
            'pod_events': self.pod_events,
            'timing_analysis': self.timing_analysis,
            'service_statistics': service_data
        }
        
        with open('kubernetes_events_cold_start_analysis.json', 'w') as f:
            json.dump(output_data, f, indent=2)
        
        print(f"\nğŸ“„ Detailed results saved to: kubernetes_events_cold_start_analysis.json")
        print("âœ… Analysis Complete!")

if __name__ == "__main__":
    analyzer = KubernetesEventsAnalyzer()
    analyzer.analyze_pod_startup()
